{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9fc181f7dd72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Data downloading\n",
    "data_root = './data'\n",
    "\n",
    "# Tranform operation to covern PIL to tensor and normalize it\n",
    "transform = transforms.Compose([transforms.toTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# train=True\n",
    "train_dataset = torchvision.datasets.CIFAR10(data_room, train=True, download=True, transform=transform)\n",
    "# train=False\n",
    "test_dataset = torchvision.datasets.CIFAR10(data_room, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# shuffle=True is important for training, whatevs for testign\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize data, you are gonna wanna unnormalize it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(img):\n",
    "    img = img / 2 + 0.5\n",
    "    img = img.numpy()\n",
    "    return np.transpose(img, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "# output of conv = (w - k + 2*padding) / s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): # inherit nn.Module\n",
    "    def __init__(self, num_classes=10):\n",
    "        self.conv_layer1 = nn.conv2d(3, 6, 5) #last param mean 5x5 window for kernel\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv_layer2 = nn.conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc_layer1 = nn.Linear(16*5*5, 120) #first param is num outputs times the number of window params from prev layer\n",
    "        self.fc_layer2 = nn.Linear(120, 84)        \n",
    "        self.fc_layer3 = nn.Linear(84, num_classes) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv_layer1(x)))\n",
    "        x = self.pool(self.relu(self.conv_layer2(x)))\n",
    "        \n",
    "        #we do this because the input of the fully connected layer needs to be flattened\n",
    "        x = x.view(-1, 16*5*5) # or x.view(x.shape[0]), [4, 16, 5, 5] --> \n",
    "        x = self.relu(self.fc_layer1(x))\n",
    "        x = self.relu(self.fc_layer2(x)) \n",
    "        x = self.fc_layer3(x) #don't ReLU the last outputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 1e-3  #very important, if you learning rate is too high, your loss values will become very high\n",
    "\n",
    "net = Net() #instantiate the net we just made\n",
    "\n",
    "# if you have a GPU\n",
    "# net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate) #popular ones are Adam and SGD.\n",
    "# if you only want to optimize the params of a specific layer\n",
    "# optimizer = optim.Adam(net.fc_layer3.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad() # zero out the optimizer\n",
    "        \n",
    "        #get data from datalaoder\n",
    "        images, labels = data\n",
    "        \n",
    "        #if you have GPU, .cuda() images and labels\n",
    "        \n",
    "        #pass data through model\n",
    "        out = net(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        # print(loss.grad()) will actally give you the gradients but we dont need this\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        #calculate loss\n",
    "        \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if i % 2000 == 0\n",
    "            print('Epoch: {:d}/{:d} \\t iter: {:d} \\t loss: {:.4f}'.format(epoch, num_epochs, i, total_loss/2000)\n",
    "        \n",
    "        #update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './checkpoints/model.pth'\n",
    "torch.save(net.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "checkpoint = torch.load(save_path)\n",
    "net.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_loader, 0):\n",
    "    images, labels = data\n",
    "    \n",
    "    out = net(images)\n",
    "    _, predicted = torch.max(out, 1)\n",
    "    \n",
    "    print('Predicted: {} \\t ground truth: {}'.format(predicted, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
